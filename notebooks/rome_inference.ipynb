{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROME: Realistic one-shot mesh-based head avatars\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![extreme](../media/tease0.gif)\n",
    "\n",
    "[ROME](https://samsunglabs.github.io/rome/) Project Page Don't forget to check orignal [DECA](https://github.com/YadiraF/DECA/) project.\n",
    "\n",
    "[![Taras](https://img.shields.io/twitter/follow/t_khakhulin?style=social)](https://twitter.com/t_khakhulin)\n",
    "\n",
    "[![GitHub stars](https://img.shields.io/github/stars/samsunglabs/rome?style=social)](https://github.com/samsunglabs/rome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import importlib, warnings\n",
    "import argparse\n",
    "from glob import glob\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "from src.utils import args as args_utils\n",
    "from src.utils.processing import process_black_shape, tensor2image\n",
    "from src.utils.visuals import mask_errosion\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_modnet_path = 'MODNet/pretrained/modnet_photographic_portrait_matting.ckpt'\n",
    "default_model_path = 'data/rome.pth'\n",
    "\n",
    "parser = argparse.ArgumentParser(conflict_handler='resolve')\n",
    "parser.add_argument('--save_dir', default='.', type=str)\n",
    "parser.add_argument('--save_render', default='True', type=args_utils.str2bool, choices=[True, False])\n",
    "parser.add_argument('--model_checkpoint', default=default_model_path, type=str)\n",
    "parser.add_argument('--modnet_path', default=default_modnet_path, type=str)\n",
    "parser.add_argument('--random_seed', default=0, type=int)\n",
    "parser.add_argument('--debug', action='store_true')\n",
    "parser.add_argument('--verbose', default='False', type=args_utils.str2bool, choices=[True, False])\n",
    "args, _ = parser.parse_known_args()\n",
    "# \n",
    "parser = importlib.import_module(f'src.rome').ROME.add_argparse_args(parser)\n",
    "\n",
    "\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "args.rome_data_dir = 'data'\n",
    "args.deca_path  = 'DECA'\n",
    "\n",
    "args.model_checkpoint = default_model_path\n",
    "args.modnet_path = default_modnet_path\n",
    "\n",
    "args.align_source = True\n",
    "args.align_scale = 1.25\n",
    "args.image_size = 256\n",
    "\n",
    "args.use_distill = True\n",
    "args.use_basis_deformer = False\n",
    "\n",
    "args.deform_face_tightness = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from infer import Infer\n",
    "infer = Infer(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_root = 'data/imgs/'\n",
    "\n",
    "src_index = 0\n",
    "source_lists = glob(f'{sources_root}/*')\n",
    "\n",
    "transform_source = True\n",
    "infer.source_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "source_image  = Image.open('data/imgs/lincoln.jpg')\n",
    "driver_img  = Image.open('data/imgs/taras2.jpg')\n",
    "\n",
    "# swap\n",
    "# driver_img, source_image = source_image, driver_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out = infer.evaluate(source_image, driver_img, crop_center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "res = tensor2image(torch.cat([out['source_information']['data_dict']['source_img'][0].cpu(),\n",
    "                              out['source_information']['data_dict']['target_img'][0].cpu(),\n",
    "                        out['render_masked'].cpu(), out['pred_target_shape_img'][0].cpu()], dim=2))\n",
    "plt.imshow(res[..., ::-1])\n",
    "plt.axis('off');plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_out = infer.evaluate(source_image, Image.open('data/imgs/taras1.jpg'),\n",
    "                        source_information_for_reuse=out['source_information'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "key_to_show = 'pred_target_shape_img'\n",
    "\n",
    "\n",
    "image_cat = np.concatenate([tensor2image(out[key_to_show][0]),\n",
    "                tensor2image(new_out[key_to_show][0])], axis=1)\n",
    "plt.imshow(image_cat[..., ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video inference\n",
    "\n",
    "Download video with Jenya, thanks him a lot for this example:\n",
    "\n",
    "```sh\n",
    "wget https://www.dropbox.com/s/pht8dd901ff3vzy/jenya_driver.zip -O jenya_driver.zip\n",
    "unzip jenya_driver.zip\n",
    "mkdir data/video\n",
    "mv jenya_driver data/video/\n",
    "rm jenya_driver.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "out = dict()\n",
    "resulted_imgs = defaultdict(list)\n",
    "\n",
    "video_folder = 'data/video/jenya_driver/'\n",
    "image_frames = sorted(glob(f\"{video_folder}/*\", recursive=True), key=lambda x: int(x.split('/')[-1][:-4]))\n",
    "\n",
    "source_image = Image.open('data/imgs/lincoln.jpg')\n",
    "\n",
    "mask_hard_threshold = 0.5\n",
    "N = len(image_frames)//20\n",
    "for i in tqdm(range(0, N, 4)):\n",
    "    new_out = infer.evaluate(source_image, Image.open(image_frames[i]),\n",
    "                        source_information_for_reuse=out.get('source_information'))\n",
    "    \n",
    "    mask_pred = (new_out['pred_target_unet_mask'].cpu() > mask_hard_threshold).float()\n",
    "    mask_pred = mask_errosion(mask_pred[0].float().numpy() * 255)\n",
    "    render = new_out['pred_target_img'].cpu() * (mask_pred) + (1 - mask_pred)\n",
    "        \n",
    "    normals = process_black_shape(((new_out['pred_target_normal'][0].cpu() + 1) / 2 * mask_pred + (1 - mask_pred) ) )\n",
    "    normals[normals==0.5]=1.\n",
    "    \n",
    "    resulted_imgs['res_normal'].append(tensor2image(normals))\n",
    "    resulted_imgs['res_mesh_images'].append(tensor2image(new_out['pred_target_shape_img'][0]))\n",
    "    resulted_imgs['res_renders'].append(tensor2image(render[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(resulted_imgs['res_normal'][0])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show video results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# np array with shape (frames, height, width, channels)\n",
    "video = np.array(resulted_imgs['res_renders'])\n",
    "\n",
    "fig = plt.figure()\n",
    "im = plt.imshow(video[0,:,:,::-1])\n",
    "plt.axis('off')\n",
    "plt.close() # this is required to not display the generated image\n",
    "\n",
    "def init():\n",
    "    im.set_data(video[0,:,:,::-1])\n",
    "\n",
    "def animate(i):\n",
    "    im.set_data(video[i,:,:,::-1])\n",
    "    return im\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=video.shape[0], interval=30)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference over the folder of source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Infer over folder\n",
    "result_root_dir = 'result_examples'\n",
    "os.makedirs(result_root_dir,exist_ok=True )\n",
    "\n",
    "sources_root = 'examples'\n",
    "source_lists = glob(f'{sources_root}/*')\n",
    "image_frames = sorted(glob(f\"{video_folder}/*\", recursive=True), key=lambda x: int(x.split('/')[-1][:-4]))\n",
    "\n",
    "for src_img_path in source_lists[2:]:\n",
    "    source_name = src_img_path.split('/')[-1][:-4]\n",
    "    source_image = Image.open(src_img_path)\n",
    "#     source_image.thumbnail((256,256), Image.ANTIALIAS)\n",
    "#     data_dict = infer.process_source_for_input_dict(source_image, infer.source_transform)\n",
    "    N = len(image_frames)\n",
    "    resulted_imgs = defaultdict(list)\n",
    "    new_out = dict()\n",
    "\n",
    "    for i in tqdm(range(N)):\n",
    "        new_out = infer.evaluate(source_image, Image.open(image_frames[i]),\n",
    "                            source_information_for_reuse=new_out.get('source_information'), crop_center=True)\n",
    "\n",
    "        mask_pred = (new_out['pred_target_unet_mask'].cpu() > mask_hard_threshold).float()\n",
    "        mask_pred = mask_errosion(mask_pred[0].float().numpy() * 255)\n",
    "        render = new_out['pred_target_img'].cpu() * (mask_pred) + (1 - mask_pred)\n",
    "\n",
    "        normals = process_black_shape(((new_out['pred_target_normal'][0].cpu() + 1) / 2 * mask_pred + (1 - mask_pred) ) )\n",
    "        normals[normals==0.5]=1.\n",
    "\n",
    "        resulted_imgs['res_normal'].append(tensor2image(normals))\n",
    "        resulted_imgs['res_renders'].append(tensor2image(render[0]))\n",
    "    \n",
    "    out = cv2.VideoWriter(f'{result_root_dir}/render_{source_name}.mp4',\n",
    "                          cv2.VideoWriter_fourcc(*'mp4v'), 30, (256, 256))\n",
    "    for i in resulted_imgs['res_renders']:\n",
    "        out.write(i)\n",
    "    out.release()\n",
    "    \n",
    "    out = cv2.VideoWriter(f'{result_root_dir}/normal_{source_name}.mp4', \n",
    "                          cv2.VideoWriter_fourcc(*'mp4v'), 30, (256, 256))\n",
    "    for i in resulted_imgs['res_normal']:\n",
    "        out.write(i)\n",
    "    out.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}